{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def costFunctionForLineGivenPoints(b, a, points):\n",
    "    totalError = 0   \n",
    "    for i in range (0, len(points)):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        totalError += (y - (a*x + b))**2\n",
    "        return totalError/len(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient will act like a compass and always point us downhill to compute it, we will need to differentiate our error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepGradient(bCurrent, aCurrent, points, learningRate):\n",
    "    bGradient = 0\n",
    "    aGradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        bGradient += -(2/N) * (y - ((aCurrent*x)+ bCurrent))\n",
    "        aGradient += -(2/N) * x * (y - ((aCurrent*x)+ bCurrent))\n",
    "    newB = bCurrent - (learningRate * bGradient)\n",
    "    newA = aCurrent - (learningRate * aGradient)\n",
    "    return [newB,newA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate variable controls how large of a step we take downhill during each iteration.\n",
    "If we take too large of a step, we may step over the minimum. However if we take small steps, \n",
    "it will require many iterations to arrive at the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(points, startB, startA, learningRate, numIterations):\n",
    "    b = startB;\n",
    "    a = startA;\n",
    "    for i in range(numIterations):\n",
    "        b,a = stepGradient(b, a, array(points), learningRate)\n",
    "    return [b,a]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunction():\n",
    "    points = genfromtxt(\"data/data.csv\", delimiter=\",\")\n",
    "    learningRate = 0.0003\n",
    "    initialB = 0\n",
    "    initialA = 0\n",
    "    numberOfIterations = 1000\n",
    "    print (\"Starting gradient descent\",\"initialB:\",initialB,\"initialA:\",initialA,\" error:\",costFunctionForLineGivenPoints(initialB, initialA, points))\n",
    "    print (\"Running....\")\n",
    "    [b, a] = gradientDescent(points, initialB, initialA, learningRate, numberOfIterations)\n",
    "    print (\"After number of iterations:\", numberOfIterations,\" b:\",b,\" a:\",a,\" error:\",costFunctionForLineGivenPoints(b, a, points))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent initialB: 0 initialA: 0  error: 10.0533421975\n",
      "Running....\n",
      "After number of iterations: 1000  b: 0.207328275636  a: 1.4754171313  error: 2.70761741232\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mainFunction()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
